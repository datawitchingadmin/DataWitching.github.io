
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Transition from SQL to PySpark</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="Transition_from_SQL_to_PySpark"
                  title="Transition from SQL to PySpark"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Summary" duration="0">
        <p>這個 Codelab 主要要介紹如何將已學會的 SQL code 應用在 PySpark 中，也會介紹兩個相對應的 function</p>


      </google-codelab-step>
    
      <google-codelab-step label="建立一個新的 Materialized View" duration="0">
        <h2 is-upgraded><strong>Step 1</strong></h2>
<p>Schema → +New → Materialized View</p>
<p class="image-container"><img style="width: 601.70px" src="img/5d01cc673529beaf.png"></p>
<h2 is-upgraded><strong>Step 2</strong></h2>
<p>在語言的地方選擇 Spark Python</p>
<p>→ Edit in Notebook</p>
<p class="image-container"><img style="width: 331.50px" src="img/9769dc6705eeddf.png"></p>
<p class="image-container"><img style="width: 328.13px" src="img/a56ed2d98525a4b5.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="read - 建立 data frame" duration="0">
        <p>讀取 schema 中的 table</p>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>%pyspark
df1 = read(&#34;NYC_CitiBike.DATE_HANDLING&#34;)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/f2981714a968a487.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="建立成 Temp View 檢視表" duration="0">
        <p><code>df.createOrReplaceTempView("name")</code></p>
<p>利用 <code>df.createOrReplaceTempView</code> 建立或是取代一個 local temporary view ，並命名為 <code>name</code></p>
<aside class="special"><p><strong>TIP: </strong>括號內記得要加上雙引號或單引號</p>
</aside>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>%pyspark
df1.createOrReplaceTempView(&#34;DATE_H_VIEW&#34;)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/87eba401075e308a.png"></p>
<p>之所以要建立成檢視表，是因為在後面 spark.sql 中可以使用，如同 SQL 中的 table，但 Temp View 僅僅是暫時的，運算完 spark.sql 後還是要存成 data frame</p>
<p>運算過後的檢視表儲存成的 data frame 也可以再建立成另一個新的檢視表，再做 spark.sql 運算</p>
<p>此步驟可以重複很多次，有點類似 SQL 中的 nested query ，可以成為連續的網絡 nested structure，一個接著一個</p>
<h2 is-upgraded><strong>Example</strong></h2>
<p>這個例子就是運用建立多次的 Temp View 在 spark.sql() 中完成 JOIN 運算</p>
<p>此運算的結果是將兩個 view 結合起來，查看租借自行車的人，從A站到B站的平均使用時間，和從B站到A站的平均使用時間，是多長時間，是否有差異，進而進行分析</p>
<pre><code>%pyspark
df1 = read(&#34;NYC_CitiBike.DATE_HANDLING&#34;)
df1.createOrReplaceTempView(&#34;DATE_H_1&#34;)
df_2 = spark.sql(&#34;&#34;&#34;
SELECT  start_station_id first_station_id, start_station_name first_station_name, end_station_id second_station_id, end_station_name second_station_name,
        AVG(tripduration) avg_by_first_to_second_station
FROM DATE_H_1
WHERE start_station_id &lt;= end_station_id
GROUP BY start_station_id, start_station_name, end_station_id, end_station_name
&#34;&#34;&#34;)
df_2.createOrReplaceTempView(&#34;first_to_second&#34;)
incorta.show(df_2)</code></pre>
<pre><code>%pyspark
df3 = read(&#34;NYC_CitiBike.DATE_HANDLING&#34;)
df3.createOrReplaceTempView(&#34;DATE_H_2&#34;)
df_4 = spark.sql(&#34;&#34;&#34;
SELECT  start_station_id second_station_id, start_station_name second_station_name, end_station_id first_station_id, end_station_name first_station_name,
        AVG(tripduration) avg_by_second_to_first_station
FROM DATE_H_2
WHERE start_station_id &gt; end_station_id
GROUP BY start_station_id, start_station_name, end_station_id, end_station_name
&#34;&#34;&#34;)
df_4.createOrReplaceTempView(&#34;second_to_first&#34;)
incorta.show(df_4)</code></pre>
<pre><code>%pyspark
df_5 = spark.sql(&#34;&#34;&#34;
SELECT  first_to_second.first_station_id, 
        first_to_second.first_station_name, 
        first_to_second.second_station_id, 
        first_to_second.second_station_name, 
        first_to_second.avg_by_first_to_second_station, 
        second_to_first.avg_by_second_to_first_station
FROM first_to_second
INNER JOIN second_to_first
ON first_to_second.first_station_id = second_to_first.first_station_id 
AND first_to_second.second_station_id = second_to_first.second_station_id
ORDER BY first_to_second.avg_by_first_to_second_station
&#34;&#34;&#34;)
save(df_5)
incorta.show(df_5)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/ebb60e3562ef8107.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/e6eb2fe5d0e0959.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/f164d7ca6ca19578.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/e73e16e996f637f7.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/e4cbfb69057c6862.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/c1a9e891e598c6da.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="spark.sql" duration="0">
        <p><code>spark.sql("""</code></p>
<p><code>SELECT .. FROM view </code></p>
<p><code>""")</code></p>
<p>要用 PySpark 寫 SQL 時，要用 <code>spark.sql</code> 指令，雙引號內即可寫 SQL code</p>
<p>創建另一個新的 df</p>
<aside class="special"><p><strong>TIP: </strong>SQL code 通常都會很長，需要換行，所以前後都要加上三個雙引號</p>
</aside>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>%pyspark
df_2 = spark.sql(&#34;&#34;&#34;
SELECT  start_station_id first_station_id, start_station_name first_station_name, end_station_id second_station_id, end_station_name second_station_name,
        AVG(tripduration) avg_by_first_to_second_station
FROM DATE_H_1
WHERE start_station_id &lt;= end_station_id
GROUP BY start_station_id, start_station_name, end_station_id, end_station_name
&#34;&#34;&#34;)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/f3cd41a710ceba73.png"></p>
<h2 is-upgraded><strong>為什麼要這樣做呢？</strong></h2>
<p>我們之所以要利用 pyspark 來做 SQL 運算是因為，若是先學習如何使用SQL做資料處理的話，有些人比較習慣 SQL 的思考邏輯，因此喜歡用 SQL 來做，但是用spark.sql又可以利用一些pyspark 的功能做其他的運算，因此用 spark.sql</p>


      </google-codelab-step>
    
      <google-codelab-step label="incorta.show(df)" duration="0">
        <p><code>incorta.show(df)</code></p>
<p>可以使用此指令來用 incorta 來顯示 data frame 的結果</p>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>%pyspark
incorta.show(df_2)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/cb40d2a485452fe1.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="df.columns" duration="0">
        <p><code>df.columns</code></p>
<p>可以查看 data 的 column names</p>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>df_2.columns</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/d6945e26a57788d0.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="df.filter" duration="0">
        <p><code>df.filter("條件")</code></p>
<p>相當於 SQL 中的 WHERE，根據所給條件篩選需要的 data</p>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>df_2 = df_2.filter(&#34;first_station_id = second_station_id&#34;)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/944082a69aad21da.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="df.count" duration="0">
        <p><code>df.count() </code></p>
<p>可以用在計算資料的筆數</p>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>%pyspark
df_5.count()</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/1351014d1bd5f6fb.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="save" duration="0">
        <p><code>save(df)</code></p>
<p>每當寫完 pyspark code 時，必須要用 save(df) 指令儲存結果</p>
<aside class="special"><p><strong>TIP: </strong>PySpark 一定會是開始於 read() ，結束於 save()</p>
</aside>
<h2 is-upgraded><strong>Example</strong></h2>
<pre><code>save(df_2)</code></pre>
<p class="image-container"><img style="width: 601.70px" src="img/915e2b837ce0aa4f.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="save job errors" duration="0">
        <p>當要儲存時若出現此錯誤，首先要先檢查 notebook 內是否有錯誤，重新 run 一次是否都可以成功跑出結果，第二個要檢查需要儲存的 paragraph 的 綠色勾勾✅是否都有勾起來，若是檢查沒問題，run 也沒問題，那就要在 notebook 外面的 Properties 加上 <code>spark.dataframe.sampling.enabled = false</code> ，步驟如下圖所示：</p>
<p class="image-container"><img style="width: 601.70px" src="img/c47d7541739944ac.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/950935952f1bfe16.png"></p>
<p class="image-container"><img style="width: 601.70px" src="img/1519f80a73c1ed20.png"></p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
